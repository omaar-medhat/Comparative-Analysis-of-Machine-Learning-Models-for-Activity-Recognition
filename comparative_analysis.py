# -*- coding: utf-8 -*-
"""Comparative Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10ghkePa6q-QoncTf5HfwPlifTv8naFeo
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import sklearn
import sklearn
print(sklearn.__version__)
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score, classification_report
from collections import Counter
from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score

!pip install -U scikit-learn

"""# **Load Data**"""

# Load your dataset
df = pd.read_csv('/content/mhealth_raw_data.csv')
df

"""# **preprocessing**"""

df.describe()

df.info()

#check for missing data
missing_values = df.isnull().sum()
missing_values

#check duplicates
duplicate_count = df.duplicated().sum()
duplicate_count

##select all rows and all columns except the last one.
X = df.iloc[:, :-1]
X
##select all rows, but only the last column.
y = df.iloc[:, -1]
y

"""
# visualization"""

numerical_columns = df.select_dtypes(include='number').columns
categorical_columns = df.select_dtypes(include='object').columns

corr = df[numerical_columns].corr()
plt.figure(figsize=(14, 9))
sns.heatmap(corr, cmap='coolwarm', annot=True)

df.hist(figsize=(17, 12))

df[categorical_columns].nunique()

plt.figure(figsize=(10, 7))
sns.countplot(df, x='Activity')

df.subject

df.shape

"""# KNN"""

import pandas as pd
from sklearn.model_selection import train_test_split
import numpy as np




# Create a representative subset of the data, e.g., 10% of the data
subset_data = df.sample(frac=0.1, random_state=42)

# Split the subset into training AND validation and test
# split into training (70% of subset) and temp (REMAIN 30% of subset)
X_train, X_temp, y_train, y_temp = train_test_split(subset_data.drop(columns=['Activity', 'subject']), subset_data['Activity'], test_size=0.3, random_state=42)

# Now split the temp into validation and test sets (each will be 15% of the original subset)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Convert all arrays to numpy arrays for compatibility with most ML libraries
X_train = np.asarray(X_train)
y_train = np.asarray(y_train)
X_val = np.asarray(X_val)
y_val = np.asarray(y_val)
X_test = np.asarray(X_test)
y_test = np.asarray(y_test)

from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
# Initialize the StandardScaler
scaler = StandardScaler()

# Fit on the training data and transform the train, test, and validation sets
X_train_scaled = scaler.fit_transform(X_train)

X_val_scaled = scaler.transform(X_val)

X_test_scaled = scaler.transform(X_test)

train_accuracies = []
val_accuracies = []
test_accuracies = []

neighbors = range(1,10)
for neighbor in neighbors:
    knn = KNeighborsClassifier(n_neighbors=neighbor)
    knn.fit(X_train_scaled, y_train)

    # Predict on the training set and calculate accuracy
    y_pred_train = knn.predict(X_train_scaled)
    train_acc = accuracy_score(y_train, y_pred_train)
    train_accuracies.append(train_acc)

    # Predict on the validation set and calculate accuracy
    y_pred_val = knn.predict(X_val_scaled)
    val_acc = accuracy_score(y_val, y_pred_val)
    val_accuracies.append(val_acc)

    # Predict on the test set and calculate accuracy
    y_pred_test = knn.predict(X_test_scaled)
    test_acc = accuracy_score(y_test, y_pred_test)
    test_accuracies.append(test_acc)

print("Training Accuracies:", train_accuracies)

print("Validation Accuracies:", val_accuracies)

print("Test Accuracies:", test_accuracies)

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=9)
knn.fit(X_train_scaled, y_train)

knn.score(X_train_scaled, y_train)

knn.score(X_test_scaled, y_test)

plt.figure(figsize=(12, 9))
plt.plot(neighbors, train_accuracies, label="Training Accuracy")

plt.plot(neighbors, test_accuracies, label = "Test Accuracy")
plt.title("KNN: Varying Number of Neighbors")
plt.legend()
plt.xlabel("Neighbors")
plt.ylabel("Accuracy")
plt.grid(True, which='both', axis='both', linestyle='-', linewidth=0.5)
plt.xticks(ticks=neighbors)
plt.show()

from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# "precision","recall","f1-score","support"
KNN_report = classification_report(y_test, y_pred_test)
print(KNN_report)

# Confusion matrix
KNN_Confusion= confusion_matrix(y_test, y_pred_test)
plt.figure(figsize=(8, 6))
sns.heatmap(KNN_Confusion, annot=True, cmap='Blues', fmt='d')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

"""# Linear Regression"""

from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.linear_model import LinearRegression

df.drop('subject', axis=1, inplace=True)

x = df.iloc[: , : -1]
# Scaling the data
scaler = StandardScaler()
scaler.fit(x)
x = scaler.transform(x)
x

y = df.iloc[: , -1]
y

from sklearn.model_selection import train_test_split
# Initialize the Linear Regression model
x_train , x_test , y_train , y_test = train_test_split(x , y , test_size = 0.3 , shuffle = True , random_state = 0)

x_train = np.asarray(x_train)
y_train = np.asarray(y_train)

x_test = np.asarray(x_test)
y_test = np.asarray(y_test)

print(x_train.shape)
print(x_test.shape)

# Normalize the data
scaler = StandardScaler().fit(x_train)
#Apply the normalizer on the train data
x_train_normalized = scaler.transform(x_train)
#Apply the normalizer on the test data
x_test_normalized = scaler.transform(x_test)
print(x_train_normalized)

lin_reg_scaled = LinearRegression()


lin_reg_scaled.fit(x_train_normalized, y_train)


training_score = lin_reg_scaled.score(x_train_normalized, y_train)

test_score = lin_reg_scaled.score(x_test_normalized, y_test)

print("Training Score (Scaled):", training_score)
print("test Score (Scaled):", test_score)

from sklearn.metrics import mean_squared_error, r2_score
# Predict using the scaled test set
y_pred = lin_reg_scaled.predict(x_test_normalized)

# Calculate the R² score and MSE
r2 = r2_score(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)

# Output the performance metrics
print(f"R² Score on Test Data: {r2}")
print(f"Mean Squared Error on Test Data: {mse}")
print(f"Root Mean Squared Error on Test Data: {rmse}")

"""# Polynomial features"""

from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score
from sklearn.preprocessing import PolynomialFeatures



# polynomial features
poly = PolynomialFeatures(2)
X_train_poly = poly.fit_transform(x_train)
X_test_poly = poly.transform(x_test)



#  Linear Regression model
lr = LinearRegression()
lr.fit(X_train_poly, y_train)

y_test_pred = lr.predict(X_test_poly)


lr.score(X_train_poly, y_train), lr.score(X_test_poly, y_test)

from sklearn.model_selection import KFold
kf = KFold(n_splits=5)
lin_cv_results = cross_val_score(lr, X_train_poly, y_train, cv=kf)
print("Cross-validation results:", lin_cv_results)
print("Mean CV accuracy:", lin_cv_results.mean())

from sklearn.metrics import mean_squared_error
import numpy as np

# calculate
mse = mean_squared_error(y_test, y_test_pred)
rmse = np.sqrt(mse)
print("(MSE): ", mse)
print("(RMSE): ", rmse)

"""# SVM"""

from mlxtend.plotting import plot_decision_regions
from sklearn.svm import SVC

print("Initial class distribution:")
print(df['Activity'].value_counts())

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# SVM model
svm_model = SVC(C=5, kernel='rbf', gamma=0.5)

# Fit the model on the training data
svm_model.fit(X_train_scaled, y_train)

# Predict on the validation
y_val_pred = svm_model.predict(X_val_scaled)
val_accuracy = accuracy_score(y_val, y_val_pred)
print(f'Validation Accuracy with "rbf" kernel: {val_accuracy:.2f}')

# After validating predict and evaluate on  test
y_test_pred = svm_model.predict(X_test_scaled)
test_accuracy = accuracy_score(y_test, y_test_pred)
print(f'Test Accuracy with "rbf" kernel: {test_accuracy:.2f}')

SVM_report = classification_report(y_test, y_test_pred)
print(SVM_report)

from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay
# Confusion matrix
cm_svm = confusion_matrix(y_test, y_test_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm_svm, annot=True, cmap='Blues', fmt='d')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

"""# Nueral network"""

from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler
from keras.models import Sequential
from keras.layers import Dense
from sklearn.model_selection import train_test_split

# Update the file path as needed
X = df.drop(['Activity', 'subject'], axis=1)
y = df['Activity']


min_max_scaler = MinMaxScaler()
X_scaled = min_max_scaler.fit_transform(X)

# Encode
encoder = OneHotEncoder(sparse_output=False)
y_encoded = encoder.fit_transform(y.values.reshape(-1, 1))

subset_data = df.sample(frac=0.1, random_state=42)
# Split the data into training and temporary (validation + test) sets
X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y_encoded, test_size=0.3, random_state=42)

# Split the temporary data into validation and test sets
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

print(X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape)

851021/512

num_classes = y_encoded.shape[1]  # Number of unique classes
num_features = X_train.shape[1]


model = Sequential([
    Dense(64, activation='relu', input_shape=(num_features,)),
    Dense(128, activation='relu'),
    Dense(64, activation='relu'),
    Dense(num_classes, activation='sigmoid')
])


model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

hist = model.fit(X_train, y_train,
                 batch_size=1024,
                 epochs=100,
                 validation_data=(X_val, y_val))

y = model.predict(X_test)

test_accuracy = model.evaluate(X_test, y_test)

print(f"Test Accuracy: {test_accuracy}")

import matplotlib.pyplot as plt

# Plot training & validation accuracy values
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(hist.history['accuracy'])
plt.plot(hist.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Val'], loc='lower right')

# Plot training & validation loss values
plt.subplot(1, 2, 2)
plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Val'], loc='upper right')

plt.tight_layout()
plt.show()

import numpy as np
from sklearn.metrics import classification_report


NN_y_predic = np.argmax(y, axis=1)
y_test_c = np.argmax(y_test, axis=1)

NN_report = classification_report(y_test_c, NN_y_predic)
print(NN_report)

# Confusion matrix
Neural_Network_Confusion= confusion_matrix(y_test_c, NN_y_predic)
plt.figure(figsize=(8, 6))
sns.heatmap(Neural_Network_Confusion, annot=True, cmap='Blues', fmt='d')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

"""# Logistic Regession"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay

from sklearn.preprocessing import LabelEncoder
X = df.drop(['Activity', 'subject'] , axis=1)
y = df['Activity']

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

encoder = LabelEncoder()
y_encoded = encoder.fit_transform(y)


subset_data = df.sample(frac=0.1, random_state=42)

# Split the data into training and temporary (validation + test) sets
X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y_encoded, test_size=0.3, random_state=42)

# Split the temporary data into validation and test sets
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

print(X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape)

clf = LogisticRegression()

# Fit the model on the training data
clf.fit(X_train, y_train)

# Predict on validation set
y_val_pred = clf.predict(X_val)

# Evaluate the model on the validation data
val_accuracy = accuracy_score(y_val, y_val_pred)
print(f'Validation Accuracy: {val_accuracy}')

y_test_pred = clf.predict(X_test)
test_accuracy = accuracy_score(y_test, y_test_pred)
print(f'Test Accuracy: {test_accuracy}')

Logistic = cross_val_score(clf, X_train, y_train, cv=5)
print("Cross-validation results:", Logistic)
print("Mean CV accuracy:", Logistic.mean())

"""# report"""

print(classification_report(y_test, y_test_pred))

"""# Confusion matrix"""

# Confusion matrix
Logistic_Regression_matrix= confusion_matrix(y_test, y_test_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(Logistic_Regression_matrix, annot=True, cmap='Blues', fmt='d')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()